{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29d1808f",
   "metadata": {},
   "source": [
    "Aluno: Vitor Albuquerque de Paula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94a7791",
   "metadata": {},
   "source": [
    "# Aplique o KNN com K = 3 para classificar o 11o elemento da tabela. Considere a distância Euclidiana e Manhattan, compare e há diferença entre elas.\n",
    "\n",
    "|    | A1 | A2 | Classe |\n",
    "|----|----|----|--------|\n",
    "| 1  | 0.5| 1  | 2      |\n",
    "| 2  | 2.9| 1.9| 2      |\n",
    "| 3  | 1.2| 3.1| 2      |\n",
    "| 4  | 0.8| 4.7| 2      |\n",
    "| 5  | 2.7| 5.4| 2      |\n",
    "| 6  | 8.1| 4.7| 1      |\n",
    "| 7  | 8.3| 6.6| 1      |\n",
    "| 8  | 6.3| 6.7| 1      |\n",
    "| 9  | 8  | 9.1| 1      |\n",
    "| 10 | 5.4| 8.4| 1      |\n",
    "| 11 | 5  | 7  | ?      |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bb0098",
   "metadata": {},
   "source": [
    "Vamos aplicar o KNN com K=3 para classificar o 11º elemento da tabela. Primeiro, calculamos as distâncias Euclidiana e Manhattan entre o 11º elemento (5, 7) e todos os outros elementos da tabela.\n",
    "\n",
    "**Distâncias Euclidianas:**\n",
    "\n",
    "1. d(1, 11) = sqrt((0.5-5)² + (1-7)²) = sqrt(4.5² + (-6)²) = sqrt(20.25 + 36) = sqrt(56.25) ≈ 7.5\n",
    "2. d(2, 11) = sqrt((2.9-5)² + (1.9-7)²) = sqrt((-2.1)² + (-5.1)²) = sqrt(4.41 + 26.01) = sqrt(30.42) ≈ 5.5\n",
    "3. d(3, 11) = sqrt((1.2-5)² + (3.1-7)²) = sqrt((-3.8)² + (-3.9)²) = sqrt(14.44 + 15.21) = sqrt(29.65) ≈ 5.44\n",
    "4. d(4, 11) = sqrt((0.8-5)² + (4.7-7)²) = sqrt((-4.2)² + (-2.3)²) = sqrt(17.64 + 5.29) = sqrt(22.93) ≈ 4.79\n",
    "5. d(5, 11) = sqrt((2.7-5)² + (5.4-7)²) = sqrt((-2.3)² + (-1.6)²) = sqrt(5.29 + 2.56) = sqrt(7.85) ≈ 2.8\n",
    "6. d(6, 11) = sqrt((8.1-5)² + (4.7-7)²) = sqrt(3.1² + (-2.3)²) = sqrt(9.61 + 5.29) = sqrt(14.9) ≈ 3.86\n",
    "7. d(7, 11) = sqrt((8.3-5)² + (6.6-7)²) = sqrt(3.3² + (-0.4)²) = sqrt(10.89 + 0.16) = sqrt(11.05) ≈ 3.32\n",
    "8. d(8, 11) = sqrt((6.3-5)² + (6.7-7)²) = sqrt(1.3² + (-0.3)²) = sqrt(1.69 + 0.09) = sqrt(1.78) ≈ 1.33\n",
    "9. d(9, 11) = sqrt((8-5)² + (9.1-7)²) = sqrt(3² + 2.1²) = sqrt(9 + 4.41) = sqrt(13.41) ≈ 3.66\n",
    "10. d(10, 11) = sqrt((5.4-5)² + (8.4-7)²) = sqrt(0.4² + 1.4²) = sqrt(0.16 + 1.96) = sqrt(2.12) ≈ 1.46\n",
    "\n",
    "**Distâncias de Manhattan (distância L1):**\n",
    "\n",
    "1. d(1, 11) = |0.5-5| + |1-7| = 4.5 + 6 = 10.5\n",
    "2. d(2, 11) = |2.9-5| + |1.9-7| = 2.1 + 5.1 = 7.2\n",
    "3. d(3, 11) = |1.2-5| + |3.1-7| = 3.8 + 3.9 = 7.7\n",
    "4. d(4, 11) = |0.8-5| + |4.7-7| = 4.2 + 2.3 = 6.5\n",
    "5. d(5, 11) = |2.7-5| + |5.4-7| = 2.3 + 1.6 = 3.9\n",
    "6. d(6, 11) = |8.1-5| + |4.7-7| = 3.1 + 2.3 = 5.4\n",
    "7. d(7, 11) = |8.3-5| + |6.6-7| = 3.3 + 0.4 = 3.7\n",
    "8. d(8, 11) = |6.3-5| + |6.7-7| = 1.3 + 0.3 = 1.6\n",
    "9. d(9, 11) = |8-5| + |9.1-7| = 3 + 2.1 = 5.1\n",
    "10. d(10, 11) = |5.4-5| + |8.4-7| = 0.4 + 1.4 = 1.8\n",
    "\n",
    "Agora vamos pegar os 3 vizinhos mais próximos para cada métrica de distância.\n",
    "\n",
    "**Métrica Euclidiana:**\n",
    "\n",
    "- Elemento 8 (distância ≈ 1.33)\n",
    "- Elemento 10 (distância ≈ 1.46)\n",
    "- Elemento 5 (distância ≈ 2.8)\n",
    "\n",
    "**Métrica de Manhattan:**\n",
    "\n",
    "- Elemento 8 (distância 1.6)\n",
    "- Elemento 10 (distância 1.8)\n",
    "- Elemento 5 (distância 3.9)\n",
    "\n",
    "Para ambas as métricas, os 3 vizinhos mais próximos são os mesmos e têm as seguintes classes: {1, 1, 2}. Como a classe 1 aparece duas vezes e a classe 2 aparece apenas uma vez, a classe do elemento 11 é 1.\n",
    "\n",
    "Então, aplicando o KNN com K=3, a classe do elemento 11 é 1, para ambas as distâncias Euclidiana e Manhattan. Não há diferença entre os resultados obtidos com as duas métricas neste caso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6481c760",
   "metadata": {},
   "source": [
    "# Aplique o algoritmo de Bayes no problema a seguir:\n",
    "\n",
    "| Name        | Give Birth | Can Fly | Live in Water | Have Legs | Class         |\n",
    "|-------------|------------|---------|---------------|-----------|---------------|\n",
    "| human       | yes        | no      | no            | yes       | mammals       |\n",
    "| python      | no         | no      | no            | no        | non-mammals   |\n",
    "| salmon      | no         | no      | yes           | no        | non-mammals   |\n",
    "| whale       | yes        | no      | yes           | no        | mammals       |\n",
    "| frog        | no         | no      | sometimes     | yes       | non-mammals   |\n",
    "| komodo      | no         | no      | no            | yes       | non-mammals   |\n",
    "| bat         | yes        | yes     | no            | yes       | mammals       |\n",
    "| pigeon      | no         | yes     | no            | yes       | non-mammals   |\n",
    "| cat         | yes        | no      | no            | yes       | mammals       |\n",
    "| leopard shark | no       | no      | yes           | no        | non-mammals   |\n",
    "| turtle      | no         | no      | sometimes     | yes       | non-mammals   |\n",
    "| penguin     | no         | no      | sometimes     | yes       | non-mammals   |\n",
    "| porcupine   | yes        | no      | no            | yes       | mammals       |\n",
    "| eel         | no         | no      | yes           | no        | non-mammals   |\n",
    "| salamander  | no         | no      | sometimes     | yes       | non-mammals   |\n",
    "| glia monster | no        | no      | no            | yes       | non-mammals   |\n",
    "| platypus    | no         | no      | no            | yes       | mammals       |\n",
    "| owl         | no         | no      | no            | yes       | non-mammals   |\n",
    "| dolphin     | yes        | no      | yes           | no        | mammals       |\n",
    "| eagle       | no         | yes     | no            | no        | non-mammals   |\n",
    "\n",
    "| Give Birth | Can Fly | Live in Water | Have Legs | Class |\n",
    "|------------|---------|---------------|-----------|-------|\n",
    "| yes        | no      | yes           | no        | ???   |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0cacd3",
   "metadata": {},
   "source": [
    "Vamos aplicar o algoritmo de Bayes para classificar o animal desconhecido com as características: dá à luz (yes), não voa (no), vive na água (yes) e não tem pernas (no). \n",
    "\n",
    "Primeiro, contamos a frequência de cada classe e suas características no conjunto de dados.\n",
    "\n",
    "Mamíferos (M) : 7\n",
    "Não mamíferos (NM) : 13\n",
    "\n",
    "| Característica | M (yes) | M (no) | NM (yes) | NM (no) |\n",
    "|----------------|---------|--------|----------|---------|\n",
    "| Give Birth     | 6       | 1      | 1        | 12      |\n",
    "| Can Fly        | 1       | 6      | 3        | 10      |\n",
    "| Live in Water  | 2       | 5      | 8        | 6       |\n",
    "| Have Legs      | 6       | 1      | 10       | 3       |\n",
    "\n",
    "Agora, vamos calcular as probabilidades das características dadas a classe: P(Característica | Classe).\n",
    "\n",
    "| Característica | P(Característica∣M) | P(Característica∣NM) |\n",
    "|----------------|----------------------|-----------------------|\n",
    "| Give Birth     | 6/7 ≈ 0.86           | 1/13 ≈ 0.08           |\n",
    "| Can Fly        | 1/7 ≈ 0.14           | 3/13 ≈ 0.23           |\n",
    "| Live in Water  | 2/7 ≈ 0.29           | 8/13 ≈ 0.62           |\n",
    "| Have Legs      | 6/7 ≈ 0.86           | 10/13 ≈ 0.77          |\n",
    "\n",
    "Agora podemos calcular as probabilidades para cada classe: P(M) e P(NM).\n",
    "\n",
    "P(M) = 7/20 = 0.35\n",
    "P(NM) = 13/20 = 0.65\n",
    "\n",
    "Agora vamos aplicar o teorema de Bayes:\n",
    "\n",
    "P(M∣Características) proporcional a P(Give Birth∣M) * P(Can Fly∣M) * P(Live in Water∣M) * P(Have Legs∣M) * P(M)\n",
    "\n",
    "P(M∣Características) proporcional a 0.86 * 0.14 * 0.29 * 0.14 * 0.35 ≈ 0.0011\n",
    "\n",
    "P(NM∣Características) proporcional a P(Give Birth∣NM) * P(Can Fly∣NM) * P(Live in Water∣NM) * P(Have Legs∣NM) * P(NM)\n",
    "\n",
    "P(NM∣Características) proporcional a 0.08 * 0.23 * 0.62 * 0.77 * 0.65 ≈ 0.0076\n",
    "\n",
    "Podemos normalizar esses valores pela soma das duas probabilidades para obter a probabilidade final.\n",
    "\n",
    "P(M∣Características) = 0.0011 / (0.0011 + 0.0076) ≈ 0.126\n",
    "\n",
    "P(NM∣Características) = 0.0076 / (0.0011 + 0.0076) ≈ 0.874\n",
    "\n",
    "Como P(NM∣Características) é maior do que P(M∣Características), o algoritmo de Bayes classifica o animal desconhecido como \"não mamífero\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d279171",
   "metadata": {},
   "source": [
    "# Execute árvores de decisão:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11115b6b",
   "metadata": {},
   "source": [
    "## a AND b\n",
    "\n",
    "Uma árvore de decisão para a operação AND pode ser representada da seguinte maneira:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fa5de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "      [a]\n",
    "     /   \\\n",
    "  [b]   [0]\n",
    " /   \\\n",
    "[1] [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e0065c",
   "metadata": {},
   "source": [
    "\n",
    "Nesta árvore, primeiro verificamos o valor de \"a\". Se \"a\" for falso (0), a resposta é \"0\". Se \"a\" for verdadeiro (1), passamos para o nó seguinte e verificamos o valor de \"b\". Se \"b\" for verdadeiro (1), a resposta é \"1\"; caso contrário, a resposta é \"0\".\n",
    "\n",
    "## a XOR b\n",
    "\n",
    "Uma árvore de decisão para a operação XOR pode ser representada da seguinte maneira:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c259c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "       [a]\n",
    "      /   \\\n",
    "    [b]   [b]\n",
    "   /   \\ /   \\\n",
    " [0] [1] [1] [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c5fbc6",
   "metadata": {},
   "source": [
    "Nesta árvore, primeiro verificamos o valor de \"a\". Se \"a\" for falso (0), passamos para o nó à esquerda e verificamos o valor de \"b\". Nesse caso, a saída é igual a \"b\". Se \"a\" for verdadeiro (1), passamos para o nó à direita e verificamos o valor de \"b\". Nesse caso, a saída é o inverso de \"b\" (se \"b\" for verdadeiro, a saída é falsa, e se \"b\" for falso, a saída é verdadeira).\n",
    "\n",
    "## (a AND b) OR (b AND c)\n",
    "\n",
    "Uma árvore de decisão para a operação (a AND b) OR (b AND c) pode ser representada da seguinte maneira:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4bc917",
   "metadata": {},
   "outputs": [],
   "source": [
    "         [b]\n",
    "        /   \\\n",
    "      [a]   [c]\n",
    "     /   \\ /   \\\n",
    "  [1] [1] [1] [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f8d69a",
   "metadata": {},
   "source": [
    "Nesta árvore, primeiro verificamos o valor de \"b\". Se \"b\" for falso (0), a resposta é \"0\". Se \"b\" for verdadeiro (1), passamos para os nós à esquerda e à direita. No nó à esquerda, verificamos se \"a\" é verdadeiro, e no nó à direita, verificamos se \"c\" é verdadeiro. Se pelo menos um deles for verdadeiro, a resposta é \"1\"; caso contrário, a resposta é \"0\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817e3585",
   "metadata": {},
   "source": [
    "# Calcular a medida de entropia para os dados abaixo:\n",
    "\n",
    "|  | C1 | C2 | E=? |\n",
    "|--|---|---|---|\n",
    "|  | 0 | 6 |  |\n",
    "|  | 1 | 5 |  |\n",
    "|  | 2 | 4 |  |\n",
    "|  | 3 | 3 |  |\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601238db",
   "metadata": {},
   "source": [
    "A entropia pode ser calculada pela seguinte fórmula:\n",
    "\n",
    "E(S) = - p1 * log2(p1) - p2 * log2(p2)\n",
    "\n",
    "Onde p1 e p2 são as probabilidades das duas classes (C1 e C2, neste caso).\n",
    "\n",
    "Para cada conjunto de dados:\n",
    "\n",
    "## Conjunto 1:\n",
    "C1: 0\n",
    "C2: 6\n",
    "Total: 6\n",
    "\n",
    "p(C1) = 0/6 = 0\n",
    "p(C2) = 6/6 = 1\n",
    "\n",
    "E(S) = -0 * log2(0) - 1 * log2(1)\n",
    "Dado que log2(1) = 0 e o logaritmo de 0 é indefinido, a entropia se torna 0.\n",
    "\n",
    "E(S) = 0\n",
    "\n",
    "## Conjunto 2:\n",
    "C1: 1\n",
    "C2: 5\n",
    "Total: 6\n",
    "\n",
    "p(C1) = 1/6\n",
    "p(C2) = 5/6\n",
    "\n",
    "E(S) = -1/6 * log2(1/6) - 5/6 * log2(5/6)\n",
    "E(S) ≈ 0.65\n",
    "\n",
    "## Conjunto 3:\n",
    "C1: 2\n",
    "C2: 4\n",
    "Total: 6\n",
    "\n",
    "p(C1) = 2/6 = 1/3\n",
    "p(C2) = 4/6 = 2/3\n",
    "\n",
    "E(S) = -1/3 * log2(1/3) - 2/3 * log2(2/3)\n",
    "E(S) ≈ 0.92\n",
    "\n",
    "## Conjunto 4:\n",
    "C1: 3\n",
    "C2: 3\n",
    "Total: 6\n",
    "\n",
    "p(C1) = 3/6 = 1/2\n",
    "p(C2) = 3/6 = 1/2\n",
    "\n",
    "E(S) = -1/2 * log2(1/2) - 1/2 * log2(1/2)\n",
    "E(S) = 1\n",
    "\n",
    "## Resumo dos resultados:\n",
    "1. E = 0\n",
    "2. E ≈ 0.65\n",
    "3. E ≈ 0.92\n",
    "4. E = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6858bd99",
   "metadata": {},
   "source": [
    "# Pesquise as principais diferenças entre os algoritmos de árvores de decisão: \n",
    "- **Hunt**\n",
    "- **ID3**\n",
    "- **C4.5**\n",
    "- **J4.8**\n",
    "- **C5.0**\n",
    "- **CART**\n",
    "- **Random-Forest**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8650479d",
   "metadata": {},
   "source": [
    "Aqui estão as principais diferenças entre os algoritmos de árvores de decisão especificados:\n",
    "\n",
    "##  Hunt:\n",
    "   * Constrói uma árvore de decisão de forma recursiva, partindo o conjunto de dados de treinamento em subconjuntos sucessivamente mais puros[1].\n",
    "   * Desenvolvido na década de 1960 para modelar o aprendizado humano em Psicologia, serve como base para muitos algoritmos populares de árvores de decisão, incluindo o ID3[2].\n",
    "   * É a base de muitos algoritmos de indução de árvores de decisão existentes, incluindo ID3, C4.5 e CART[3].\n",
    "\n",
    "## ID3 (Iterative Dichotomiser 3):\n",
    "   * Um dos primeiros algoritmos de árvores de decisão, desenvolvido por Ross Quinlan.\n",
    "   * Utiliza Entropia e Ganho de Informação para seleção de atributos em cada nó[4].\n",
    "\n",
    "## C4.5:\n",
    "   * Extensão do algoritmo ID3 criada por Ross Quinlan.\n",
    "   * Utiliza a razão de ganho para a seleção de atributos, além de lidar com valores de atributos contínuos e dados ausentes.\n",
    "   * Implementa métodos de poda para evitar o sobreajuste.\n",
    "\n",
    "## J4.8:\n",
    "   * Implementação do algoritmo C4.5 na linguagem Java.\n",
    "   * Permite a classificação por meio de árvores de decisão ou regras geradas a partir delas, construindo árvores de decisão baseadas em um conjunto de dados de treinamento da mesma forma que o ID3[5].\n",
    "   * Implementa uma versão mais recente e ligeiramente melhorada chamada C4.5 revisão 8[6].\n",
    "\n",
    "## C5.0:\n",
    "   * Versão comercial e mais rápida do algoritmo C4.5, também desenvolvida por Ross Quinlan.\n",
    "   * Oferece melhorias em termos de velocidade, memória e usabilidade em relação ao C4.5[4].\n",
    "\n",
    "## CART (Classification and Regression Trees):\n",
    "   * Podendo ser utilizado tanto para classificação quanto para regressão.\n",
    "   * Utiliza o índice Gini ou a redução na variância para a seleção de atributos, diferentemente do ID3 e C4.5 que usam medidas baseadas em entropia[4].\n",
    "\n",
    "## Random Forest:\n",
    "   * Método de aprendizado em conjunto para classificação, regressão e outras tarefas que opera construindo uma multidão de árvores de decisão durante o tempo de treinamento.\n",
    "   * Combina a saída de múltiplas árvores de decisão para alcançar um único resultado, melhorando a precisão e a estabilidade das previsões[8].\n",
    "\n",
    "## Links das Fontes:\n",
    "- [Bookdown](https://bookdown.org/mwheeler/masters/hunts-algorithm.html)[1]\n",
    "- [IBM (Hunt)](https://www.ibm.com/cloud/learn/decision-trees)[2]\n",
    "- [AI from scratch (Hunt)](https://devitrylouis.github.io/Decision_trees/)[3]\n",
    "- [PUC-Rio](http://www.maxwell.vrac.puc-rio.br/9947/9947.PDF)[4]\n",
    "- [Medium (J4.8)](https://medium.com/swlh/j48-classification-c4-5-algorithm-in-a-nutshell-b2087b819d5f)[5]\n",
    "- [ScienceDirect Topics (J4.8)](https://www.sciencedirect.com/topics/computer-science/decision-tree-learner)[6]\n",
    "- [Built In (Random Forest)](https://builtin.com/data-science/random-forest-algorithm)[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6ea4c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
