{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c656bf78",
   "metadata": {},
   "source": [
    "Vitor Albuquerque de Paula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e197ee61",
   "metadata": {},
   "source": [
    "# Considere o seguinte conjunto de treinamento. Classifique com kNN (k = 1) a sentença:\n",
    "“I always like foreign films”. Compare a distância Cosseno com Euclidiana.\n",
    "\n",
    "| Classe     | Texto                               |\n",
    "|------------|-------------------------------------|\n",
    "| Negativo (-) | Just plain boring                   |\n",
    "| Negativo (-) | Entirely predictable and lacks energy |\n",
    "| Negativo (-) | No surprises and very few laughs    |\n",
    "| Positivo (+) | Very powerful                       |\n",
    "| Positivo (+) | The most fun film of the summer     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75f09cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frase: 'Just plain boring'\n",
      "   Distância Cosseno: 0.0\n",
      "   Distância Euclidiana: 2.6457513110645907\n",
      "Frase: 'Entirely predictable and lacks energy'\n",
      "   Distância Cosseno: 0.0\n",
      "   Distância Euclidiana: 3.0\n",
      "Frase: 'No surprises and very few laughs'\n",
      "   Distância Cosseno: 0.0\n",
      "   Distância Euclidiana: 3.1622776601683795\n",
      "Frase: 'Very powerful'\n",
      "   Distância Cosseno: 0.0\n",
      "   Distância Euclidiana: 2.449489742783178\n",
      "Frase: 'The most fun film of the summer'\n",
      "   Distância Cosseno: 0.0\n",
      "   Distância Euclidiana: 3.605551275463989\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "import numpy as np\n",
    "\n",
    "# Sentenças do conjunto de treinamento e a sentença a ser classificada\n",
    "sentences = [\n",
    "    \"Just plain boring\",\n",
    "    \"Entirely predictable and lacks energy\",\n",
    "    \"No surprises and very few laughs\",\n",
    "    \"Very powerful\",\n",
    "    \"The most fun film of the summer\",\n",
    "    \"I always like foreign films\"\n",
    "]\n",
    "\n",
    "# Vectorizando as sentenças\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(sentences).toarray()\n",
    "\n",
    "# Calculando as distâncias para a sentença a ser classificada\n",
    "target_sentence_vector = X[-1]\n",
    "training_vectors = X[:-1]\n",
    "\n",
    "# Distância Cosseno\n",
    "cosine_distances = cosine_similarity([target_sentence_vector], training_vectors)\n",
    "\n",
    "# Distância Euclidiana\n",
    "euclidean_distances = euclidean_distances([target_sentence_vector], training_vectors)\n",
    "\n",
    "(cosine_distances, euclidean_distances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1914ba0",
   "metadata": {},
   "source": [
    "A análise das distâncias entre a sentença \"I always like foreign films\" e as sentenças do conjunto de treinamento revelou os seguintes resultados:\n",
    "\n",
    "**Distância Cosseno:** Todas as distâncias coseno são 0, indicando que, sob essa métrica, a sentença de interesse não tem semelhança com nenhuma das sentenças do conjunto de treinamento. Isso pode ser devido à escolha de palavras únicas na vetorização, que não captura bem a semelhança semântica. \n",
    "\n",
    "**Distância Euclidiana:** As distâncias variam, com a menor distância sendo para a sentença \"Very powerful\" (2.44948974). Portanto, usando a distância Euclidiana, a sentença \"I always like foreign films\" seria classificada como \"Positivo (+)\".\n",
    "\n",
    "Devido à discrepância entre as métricas, é importante notar que a escolha da técnica de vetorização e a métrica de distância podem ter um impacto significativo nos resultados do kNN. A distância Cosseno é geralmente preferida para dados de texto, pois é mais sensível ao ângulo entre os vetores (ou seja, a direção das palavras no espaço vetorial) do que à sua magnitude. No entanto, a vetorização simples usada aqui pode não ser adequada para capturar a semântica das sentenças de forma eficaz. Métodos mais avançados, como TF-IDF ou incorporações de palavras (word embeddings), poderiam oferecer uma representação mais rica e talvez resultar em uma classificação mais precisa. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b07ae4",
   "metadata": {},
   "source": [
    "# Considere o seguinte conjunto de treinamento. Classifique com Naive Bayes a sentença: “eu gosto deste lugar”\n",
    "\n",
    "| Classe     | Texto                         |\n",
    "|------------|-------------------------------|\n",
    "| Negativo (-) | eu não gosto deste restaurante |\n",
    "| Negativo (-) | estou cansado dessas coisas    |\n",
    "| Positivo (+) | eu me sinto bem com essas cervejas |\n",
    "| Positivo (+) | eu amo esse sanduíche           |\n",
    "| Positivo (+) | este é um lugar incrível!       |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8f3b0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A sentença 'eu gosto deste lugar' foi classificada como: Negativo\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "# Dados de treinamento\n",
    "training_data = [\n",
    "    (\"Negativo\", \"eu não gosto deste restaurante\"),\n",
    "    (\"Negativo\", \"estou cansado dessas coisas\"),\n",
    "    (\"Positivo\", \"eu me sinto bem com essas cervejas\"),\n",
    "    (\"Positivo\", \"eu amo esse sanduíche\"),\n",
    "    (\"Positivo\", \"este é um lugar incrível!\")\n",
    "]\n",
    "\n",
    "# Tokenização e contagem de frequência de palavras por classe\n",
    "word_freq = defaultdict(lambda: defaultdict(int))\n",
    "class_count = defaultdict(int)\n",
    "\n",
    "for label, text in training_data:\n",
    "    class_count[label] += 1\n",
    "    for word in text.split():\n",
    "        word_freq[label][word] += 1\n",
    "\n",
    "# Cálculo das probabilidades\n",
    "total_samples = sum(class_count.values())\n",
    "class_probabilities = {label: count / total_samples for label, count in class_count.items()}\n",
    "\n",
    "# Probabilidades condicionais de palavras dadas as classes\n",
    "word_probabilities = {}\n",
    "for label in word_freq:\n",
    "    total_words = sum(word_freq[label].values())\n",
    "    word_probabilities[label] = {word: (count / total_words) for word, count in word_freq[label].items()}\n",
    "\n",
    "# Classificando a nova sentença\n",
    "new_sentence = \"eu gosto deste lugar\"\n",
    "new_sentence_words = new_sentence.split()\n",
    "\n",
    "# Probabilidades de cada classe para a nova sentença\n",
    "sentence_probabilities = {}\n",
    "for label in class_probabilities:\n",
    "    sentence_prob = math.log(class_probabilities[label])  # Uso do log para evitar underflow\n",
    "    for word in new_sentence_words:\n",
    "        # Adicionando uma suavização para evitar multiplicação por zero se a palavra não estiver presente\n",
    "        word_prob = word_probabilities[label].get(word, 1 / (total_words + len(word_freq[label])))\n",
    "        sentence_prob += math.log(word_prob)\n",
    "    sentence_probabilities[label] = sentence_prob\n",
    "\n",
    "sentence_probabilities\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f642907",
   "metadata": {},
   "source": [
    "De acordo com o modelo Naive Bayes treinado com os dados fornecidos, a sentença \"eu gosto deste lugar\" é classificada como Negativo (-). Isso é determinado pela comparação das probabilidades logarítmicas, onde a sentença obteve uma maior probabilidade de pertencer à classe Negativa em comparação com a classe Positiva.\n",
    "\n",
    "É importante notar que o Naive Bayes assume independência entre as características (neste caso, palavras), o que nem sempre é verdadeiro em dados de linguagem natural. Além disso, a ausência de algumas palavras na classe Positiva pode ter influenciado o resultado"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
